{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Loopy Agents","text":"![Loopy Agents Logo](assets/banner.png)  **Master Claude Code with Advanced Hooks, Agents, and MCP Servers**  [![GitHub Stars](https://img.shields.io/github/stars/looptech-ai/loopy-agents?style=for-the-badge&amp;logo=github)](https://github.com/looptech-ai/loopy-agents) [![Documentation](https://img.shields.io/badge/docs-mkdocs-purple?style=for-the-badge)](https://looptech-ai.github.io/loopy-agents-doc) [![License](https://img.shields.io/badge/license-MIT-cyan?style=for-the-badge)](LICENSE)"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<p>Get up and running with Claude Code in minutes:</p> Install Claude CodeSetup Loopy AgentsFirst Hook Bash<pre><code># Install Claude Code CLI\nnpm install -g @anthropic/claude-code\n\n# Or use the installer\ncurl -fsSL https://claude.ai/install.sh | sh\n\n# Verify installation\nclaude --version\n</code></pre> Bash<pre><code># Clone the repository\ngit clone https://github.com/looptech-ai/loopy-agents.git\ncd loopy-agents\n\n# Install dependencies\npip install -r requirements.txt\nnpm install\n\n# Initialize configuration\n./scripts/setup.sh\n</code></pre> Python<pre><code># .claude/hooks/safety.py\nimport json\nimport sys\n\ndef pre_tool_use_hook(event):\n    \"\"\"Block dangerous commands\"\"\"\n    tool_name = event.get(\"tool_name\")\n    params = event.get(\"params\", {})\n\n    # Block dangerous bash commands\n    if tool_name == \"Bash\":\n        command = params.get(\"command\", \"\")\n        dangerous = [\"rm -rf\", \"sudo\", \"chmod 777\"]\n\n        for danger in dangerous:\n            if danger in command:\n                return {\n                    \"action\": \"block\",\n                    \"message\": f\"Blocked dangerous command: {danger}\"\n                }\n\n    return {\"action\": \"allow\"}\n\nif __name__ == \"__main__\":\n    event = json.loads(sys.stdin.read())\n    result = pre_tool_use_hook(event)\n    print(json.dumps(result))\n</code></pre>"},{"location":"#what-is-loopy-agents","title":"\ud83c\udfaf What is Loopy Agents?","text":"<p>Loopy Agents is a comprehensive framework for extending Claude Code with:</p> <ul> <li> <p>:material-hook:{ .lg .middle } Advanced Hooks</p> <p>Implement all 8 lifecycle events with security-focused patterns, validation frameworks, and JSON-based flow control</p> <p>:octicons-arrow-right-24: Learn about hooks</p> </li> <li> <p>:material-robot:{ .lg .middle } Intelligent Agents</p> <p>Create single-file agents, multi-agent systems, voice-enabled assistants, and infinite loops</p> <p>:octicons-arrow-right-24: Explore agents</p> </li> <li> <p>:material-server:{ .lg .middle } MCP Servers</p> <p>Connect to multiple LLM providers, implement custom tools, and create unified interfaces</p> <p>:octicons-arrow-right-24: Setup MCP</p> </li> <li> <p>:material-eye:{ .lg .middle } Real-time Observability</p> <p>Monitor multi-agent systems, track performance metrics, and debug with visual tools</p> <p>:octicons-arrow-right-24: View monitoring</p> </li> </ul>"},{"location":"#architecture-overview","title":"\ud83d\udcca Architecture Overview","text":"<pre><code>graph TB\n    subgraph \"Claude Code Core\"\n        CC[Claude Code CLI]\n        API[Anthropic API]\n    end\n\n    subgraph \"Loopy Agents Framework\"\n        HOOKS[Hook System]\n        AGENTS[Agent Manager]\n        MCP[MCP Servers]\n        OBS[Observability]\n    end\n\n    subgraph \"Extensions\"\n        GUI[Claudia GUI]\n        VOICE[Voice Integration]\n        MEM[Memory System]\n    end\n\n    CC --&gt; HOOKS\n    CC --&gt; AGENTS\n    CC --&gt; MCP\n\n    HOOKS --&gt; OBS\n    AGENTS --&gt; OBS\n    MCP --&gt; OBS\n\n    AGENTS --&gt; VOICE\n    HOOKS --&gt; MEM\n    MCP --&gt; GUI\n\n    style CC fill:#7c3aed\n    style HOOKS fill:#06b6d4\n    style AGENTS fill:#10b981\n    style MCP fill:#f59e0b\n    style OBS fill:#ef4444</code></pre>"},{"location":"#key-features","title":"\ud83c\udf1f Key Features","text":""},{"location":"#security-first","title":"\ud83d\udd12 Security First","text":"<ul> <li>Command blocking patterns</li> <li>Sandboxed execution</li> <li>Result validation</li> <li>Granular permissions</li> </ul>"},{"location":"#performance-optimized","title":"\u26a1 Performance Optimized","text":"<ul> <li>Parallel agent execution</li> <li>Token usage tracking</li> <li>Cost optimization</li> <li>Cache strategies</li> </ul>"},{"location":"#developer-experience","title":"\ud83c\udfa8 Developer Experience","text":"<ul> <li>Single-file agents</li> <li>Voice-enabled coding</li> <li>Visual debugging</li> <li>Hot reloading</li> </ul>"},{"location":"#team-collaboration","title":"\ud83e\udd1d Team Collaboration","text":"<ul> <li>Shared memory system</li> <li>Git-based workflows</li> <li>Multi-agent coordination</li> <li>Real-time monitoring</li> </ul>"},{"location":"#documentation-structure","title":"\ud83d\udcda Documentation Structure","text":"<ul> <li> <p>Getting Started</p> <p>Installation, setup, and your first agent</p> <ul> <li>Installation Guide</li> <li>Quick Tutorial</li> <li>Architecture Overview</li> </ul> </li> <li> <p>Core Concepts</p> <p>Deep dives into framework components</p> <ul> <li>Hook Lifecycle</li> <li>Agent Patterns</li> <li>Memory Hierarchy</li> </ul> </li> <li> <p>Advanced Topics</p> <p>Production-ready patterns and optimization</p> <ul> <li>Multi-Agent Systems</li> <li>Custom MCP Servers</li> <li>Performance Tuning</li> </ul> </li> <li> <p>Reference</p> <p>Complete API documentation and guides</p> <ul> <li>Command Reference</li> <li>API Documentation</li> <li>Troubleshooting</li> </ul> </li> </ul>"},{"location":"#example-multi-agent-system","title":"\ud83d\udee0\ufe0f Example: Multi-Agent System","text":"examples/multi_agent_system.py<pre><code>#!/usr/bin/env python3\n\"\"\"\nMulti-agent system with real-time monitoring\n\"\"\"\n\nfrom loopy_agents import AgentManager, Agent, Monitor\nfrom loopy_agents.hooks import lifecycle\nimport asyncio\n\n# Define specialized agents\nclass CodeReviewer(Agent):\n    \"\"\"Reviews code for security and style issues\"\"\"\n    system_prompt = \"\"\"You are a senior code reviewer.\n    Focus on security vulnerabilities and code quality.\"\"\"\n\n    tools = [\"Read\", \"Grep\", \"Edit\"]\n\nclass TestWriter(Agent):\n    \"\"\"Writes comprehensive test suites\"\"\"\n    system_prompt = \"\"\"You are a test automation expert.\n    Write thorough tests with edge cases.\"\"\"\n\n    tools = [\"Write\", \"Bash\", \"Edit\"]\n\nclass Documenter(Agent):\n    \"\"\"Creates and maintains documentation\"\"\"\n    system_prompt = \"\"\"You are a technical writer.\n    Create clear, comprehensive documentation.\"\"\"\n\n    tools = [\"Write\", \"Edit\", \"Read\"]\n\n# Initialize monitoring\nmonitor = Monitor(port=8080)\n\n# Create agent manager\nmanager = AgentManager(monitor=monitor)\n\n# Register agents\nmanager.register(CodeReviewer())\nmanager.register(TestWriter())\nmanager.register(Documenter())\n\n# Define workflow\nasync def development_workflow(task):\n    \"\"\"Orchestrate agents for development tasks\"\"\"\n\n    # Phase 1: Code Review\n    review_result = await manager.run_agent(\n        \"CodeReviewer\",\n        f\"Review this code for issues: {task}\"\n    )\n\n    # Phase 2: Test Creation (parallel)\n    test_task = manager.run_agent(\n        \"TestWriter\",\n        f\"Write tests based on review: {review_result}\"\n    )\n\n    # Phase 3: Documentation (parallel)\n    doc_task = manager.run_agent(\n        \"Documenter\",\n        f\"Document the implementation: {task}\"\n    )\n\n    # Wait for parallel tasks\n    test_result, doc_result = await asyncio.gather(\n        test_task, doc_task\n    )\n\n    return {\n        \"review\": review_result,\n        \"tests\": test_result,\n        \"docs\": doc_result\n    }\n\n# Run with monitoring\nif __name__ == \"__main__\":\n    # Start monitoring dashboard\n    monitor.start()\n\n    # Execute workflow\n    result = asyncio.run(\n        development_workflow(\"implement user authentication\")\n    )\n\n    print(\"Workflow completed!\", result)\n</code></pre> <p>Pro Tip</p> <p>Access the monitoring dashboard at <code>http://localhost:8080</code> to see real-time agent interactions, performance metrics, and event logs.</p>"},{"location":"#learning-path","title":"\ud83c\udf93 Learning Path","text":"<ol> <li>Beginner \u2192 Start with Getting Started</li> <li>Intermediate \u2192 Explore Hooks and Single-File Agents</li> <li>Advanced \u2192 Master Multi-Agent Systems and Custom MCP Servers</li> <li>Expert \u2192 Build Production Patterns and Team Workflows</li> </ol>"},{"location":"#community-support","title":"\ud83e\udd1d Community &amp; Support","text":"<ul> <li> <p>:material-github:{ .lg .middle } GitHub</p> <p>Star, fork, and contribute</p> <p>looptech-ai/loopy-agents</p> </li> <li> <p>:material-discord:{ .lg .middle } Discord</p> <p>Join our community</p> <p>discord.gg/loopy-agents</p> </li> <li> <p>:material-youtube:{ .lg .middle } YouTube</p> <p>Video tutorials and demos</p> <p>@looptech-ai</p> </li> <li> <p>:material-book:{ .lg .middle } Blog</p> <p>Articles and case studies</p> <p>blog.looptech.ai</p> </li> </ul>"},{"location":"#statistics","title":"\ud83d\udcc8 Statistics","text":"<ul> <li>5,000+ GitHub Stars across ecosystem</li> <li>100+ Contributors</li> <li>50+ Example agents</li> <li>10+ MCP server integrations</li> <li>8 Lifecycle hooks implemented</li> <li>24/7 Real-time monitoring</li> </ul>"},{"location":"#roadmap","title":"\ud83d\udea6 Roadmap","text":"<ul> <li> Complete hook system implementation</li> <li> Multi-agent orchestration</li> <li> Real-time observability</li> <li> Voice integration</li> <li> IDE plugins (VS Code, JetBrains)</li> <li> Cloud deployment patterns</li> <li> Enterprise features</li> <li> AI model marketplace</li> </ul>   **Ready to supercharge your Claude Code experience?**  [Get Started Now](getting-started.md){ .md-button .md-button--primary } [View Examples](examples/index.md){ .md-button }"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before installing Loopy Agents, ensure you have the following:</p> <ul> <li>Python 3.9 or higher</li> <li>Claude Code CLI</li> <li>Git</li> <li>UV (for single-file agents)</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#step-1-install-claude-code","title":"Step 1: Install Claude Code","text":"macOS/LinuxWindowsWSL2 Bash<pre><code># Install via npm\nnpm install -g @anthropic/claude-code\n\n# Or use the installer script\ncurl -fsSL https://claude.ai/install.sh | sh\n\n# Verify installation\nclaude --version\n</code></pre> PowerShell<pre><code># Install via npm\nnpm install -g @anthropic/claude-code\n\n# Or download installer from\n# https://claude.ai/download/windows\n\n# Verify installation\nclaude --version\n</code></pre> Bash<pre><code># In WSL2 terminal\ncurl -fsSL https://claude.ai/install.sh | sh\n\n# Add to PATH\necho 'export PATH=\"$HOME/.claude/bin:$PATH\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n\n# Verify installation\nclaude --version\n</code></pre>"},{"location":"getting-started/#step-2-clone-loopy-agents","title":"Step 2: Clone Loopy Agents","text":"Bash<pre><code># Clone the repository\ngit clone https://github.com/looptech-ai/loopy-agents.git\ncd loopy-agents\n\n# Install Python dependencies\npip install -r requirements.txt\n\n# Install UV for single-file agents\npip install uv\n</code></pre>"},{"location":"getting-started/#step-3-configure-environment","title":"Step 3: Configure Environment","text":"Bash<pre><code># Copy environment template\ncp .env.example .env\n\n# Edit with your API keys\nnano .env\n</code></pre> <p>Add your API keys:</p> Text Only<pre><code># Required\nANTHROPIC_API_KEY=sk-ant-xxxxx\n\n# Optional\nOPENAI_API_KEY=sk-xxxxx\nGROQ_API_KEY=gsk-xxxxx\nELEVENLABS_API_KEY=xxxxx\n\n# Configuration\nMONITORING_PORT=8080\nLOG_LEVEL=INFO\n</code></pre>"},{"location":"getting-started/#step-4-initialize-hooks","title":"Step 4: Initialize Hooks","text":"Bash<pre><code># Run the initialization script\npython scripts/init_hooks.py\n\n# This will:\n# - Create .claude/hooks/ directory\n# - Install default hooks\n# - Configure settings.json\n# - Set up monitoring\n\n# Verify hooks are installed\nclaude hooks list\n</code></pre>"},{"location":"getting-started/#your-first-agent","title":"Your First Agent","text":""},{"location":"getting-started/#create-a-simple-agent","title":"Create a Simple Agent","text":"<p>Create <code>my_agent.py</code>:</p> Python<pre><code>#!/usr/bin/env python3\n# /// script\n# requires-python = \"&gt;=3.9\"\n# dependencies = [\n#   \"openai\",\n#   \"rich\",\n# ]\n# ///\n\n\"\"\"My first Loopy Agent\"\"\"\n\nimport sys\nfrom rich.console import Console\n\nconsole = Console()\n\ndef main(task: str):\n    \"\"\"Process the task\"\"\"\n    console.print(f\"[green]Processing:[/green] {task}\")\n\n    # Your agent logic here\n    result = f\"Completed: {task}\"\n\n    console.print(f\"[cyan]Result:[/cyan] {result}\")\n    return result\n\nif __name__ == \"__main__\":\n    if len(sys.argv) &gt; 1:\n        main(sys.argv[1])\n    else:\n        console.print(\"[red]Usage:[/red] python my_agent.py &lt;task&gt;\")\n</code></pre>"},{"location":"getting-started/#run-the-agent","title":"Run the Agent","text":"Bash<pre><code># Make executable\nchmod +x my_agent.py\n\n# Run with UV (auto-installs dependencies)\n./my_agent.py \"Analyze this code\"\n\n# Or run with Python\npython my_agent.py \"Write a function\"\n</code></pre>"},{"location":"getting-started/#testing-your-setup","title":"Testing Your Setup","text":""},{"location":"getting-started/#test-hooks","title":"Test Hooks","text":"Bash<pre><code># Test safety hook (should block)\nclaude \"Delete all files with rm -rf /\"\n# Output: \u274c Blocked by safety hook\n\n# Test normal command (should work)\nclaude \"List files in current directory\"\n# Output: \u2705 Executes normally\n</code></pre>"},{"location":"getting-started/#test-monitoring","title":"Test Monitoring","text":"Bash<pre><code># Start monitoring dashboard\npython -m loopy_agents.monitor\n\n# Open browser to http://localhost:8080\n# You should see the dashboard\n\n# In another terminal, run Claude Code\nclaude \"Create a Python hello world\"\n\n# Watch events appear in dashboard\n</code></pre>"},{"location":"getting-started/#test-mcp-server","title":"Test MCP Server","text":"Bash<pre><code># Start MCP server\npython mcp_servers/multi_provider/server.py\n\n# In another terminal\nclaude --mcp multi-provider \"Compare GPT-4 and Claude responses\"\n\n# Server will route to appropriate provider\n</code></pre>"},{"location":"getting-started/#quick-examples","title":"Quick Examples","text":""},{"location":"getting-started/#hook-example","title":"Hook Example","text":".claude/hooks/user_prompt_submit.py<pre><code>#!/usr/bin/env python3\n\"\"\"Enhance user prompts before submission\"\"\"\n\nimport json\nimport sys\n\ndef enhance_prompt(event):\n    prompt = event.get(\"prompt\", \"\")\n\n    # Add context to coding requests\n    if \"function\" in prompt.lower() or \"code\" in prompt.lower():\n        prompt += \"\\n\\nPlease include: docstrings, type hints, and error handling.\"\n\n    return {\n        \"action\": \"continue\",\n        \"prompt\": prompt\n    }\n\nif __name__ == \"__main__\":\n    event = json.loads(sys.stdin.read())\n    result = enhance_prompt(event)\n    print(json.dumps(result))\n</code></pre>"},{"location":"getting-started/#agent-orchestration","title":"Agent Orchestration","text":"examples/orchestrate.py<pre><code>from loopy_agents import orchestrate\n\nasync def review_and_test(file_path):\n    \"\"\"Review code and generate tests\"\"\"\n\n    tasks = [\n        (\"code_reviewer\", f\"Review {file_path}\"),\n        (\"test_writer\", f\"Write tests for {file_path}\"),\n        (\"documenter\", f\"Document {file_path}\")\n    ]\n\n    results = await orchestrate(tasks, parallel=True)\n    return results\n\n# Run with: python examples/orchestrate.py\n</code></pre>"},{"location":"getting-started/#voice-command","title":"Voice Command","text":"examples/voice.py<pre><code>from loopy_agents.voice import listen\n\n# Start listening\ncommand = listen()\nprint(f\"You said: {command}\")\n\n# Execute with Claude\nfrom loopy_agents import execute\nresult = execute(command)\nprint(f\"Result: {result}\")\n</code></pre>"},{"location":"getting-started/#configuration-files","title":"Configuration Files","text":""},{"location":"getting-started/#claudesettingsjson","title":"<code>.claude/settings.json</code>","text":"JSON<pre><code>{\n  \"hooks\": {\n    \"preToolUse\": \".claude/hooks/pre_tool_use.py\",\n    \"postToolUse\": \".claude/hooks/post_tool_use.py\"\n  },\n  \"mcpServers\": {\n    \"multi-provider\": {\n      \"command\": \"python\",\n      \"args\": [\"mcp_servers/multi_provider/server.py\"]\n    }\n  },\n  \"security\": {\n    \"blockDangerousCommands\": true,\n    \"sandboxExecution\": true\n  }\n}\n</code></pre>"},{"location":"getting-started/#claudemd","title":"<code>CLAUDE.md</code>","text":"Markdown<pre><code># Project Context\n\n## Coding Standards\n- Use type hints in Python\n- Write comprehensive docstrings\n- Include error handling\n- Follow PEP 8\n\n## Architecture\n- Microservices pattern\n- REST APIs\n- PostgreSQL database\n- Redis caching\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Now that you have Loopy Agents installed:</p> <ol> <li>Explore Hooks - Learn about lifecycle hooks</li> <li>Create Agents - Build your first agent</li> <li>Setup Monitoring - Configure observability</li> <li>Connect MCP - Add LLM providers</li> </ol>"},{"location":"getting-started/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/#common-issues","title":"Common Issues","text":"Command 'claude' not found <p>Make sure Claude Code is in your PATH:</p> Bash<pre><code># Add to ~/.bashrc or ~/.zshrc\nexport PATH=\"$HOME/.claude/bin:$PATH\"\n\n# Reload shell\nsource ~/.bashrc\n</code></pre> ImportError: No module named 'loopy_agents' <p>Install the package in development mode:</p> Bash<pre><code>cd loopy-agents\npip install -e .\n</code></pre> Hook not triggering <p>Check your settings file:</p> Bash<pre><code># Verify hooks are configured\ncat .claude/settings.json\n\n# Test hook directly\necho '{\"tool_name\":\"Bash\",\"params\":{\"command\":\"ls\"}}' | python .claude/hooks/pre_tool_use.py\n</code></pre> MCP server timeout <p>Increase timeout in settings:</p> JSON<pre><code>{\n  \"mcpServers\": {\n    \"multi-provider\": {\n      \"timeout\": 30000\n    }\n  }\n}\n</code></pre>"},{"location":"getting-started/#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcda Read the Documentation</li> <li>\ud83d\udcac Join Discord</li> <li>\ud83d\udc1b Report Issues</li> <li>\ud83d\udcfa Watch Tutorials</li> </ul>"},{"location":"agents/","title":"Agents Overview","text":"<p>Build Powerful AI Agents</p> <p>Create single-file agents, multi-agent systems, and voice-enabled assistants using best practices from the Claude Code ecosystem.</p>"},{"location":"agents/#what-are-agents","title":"What Are Agents?","text":"<p>Agents are specialized AI assistants that perform specific tasks autonomously. They can be simple single-file scripts or complex multi-agent systems that coordinate to solve problems.</p> <pre><code>graph TB\n    subgraph \"Agent Types\"\n        A[Single-File Agent] --&gt; D[Self-contained]\n        B[Multi-Agent System] --&gt; E[Orchestrated]\n        C[Voice Agent] --&gt; F[Interactive]\n    end\n\n    D --&gt; G[Code Reviewer]\n    D --&gt; H[Test Writer]\n    E --&gt; I[Development Team]\n    F --&gt; J[Voice Assistant]</code></pre>"},{"location":"agents/#agent-architecture","title":"Agent Architecture","text":"<ul> <li> <p>:material-file-code:{ .lg .middle } Single-File Agents</p> <p>Self-contained scripts with embedded dependencies using UV</p> Python<pre><code>#!/usr/bin/env python3\n# /// script\n# requires-python = \"&gt;=3.9\"\n# dependencies = [\"openai\", \"rich\"]\n# ///\n</code></pre> </li> <li> <p>:material-robot-multiple:{ .lg .middle } Multi-Agent Systems</p> <p>Coordinated teams of specialized agents</p> Python<pre><code>manager = AgentManager()\nresults = await manager.orchestrate([\n    (\"reviewer\", task1),\n    (\"tester\", task2)\n])\n</code></pre> </li> <li> <p>:material-microphone:{ .lg .middle } Voice-Enabled Agents</p> <p>Natural language interaction with voice I/O</p> Python<pre><code>agent = VoiceAgent()\ncommand = agent.listen()\nresponse = agent.process(command)\nagent.speak(response)\n</code></pre> </li> <li> <p>:material-infinity:{ .lg .middle } Infinite Loops</p> <p>Continuous improvement through iterative refinement</p> Python<pre><code>while True:\n    result = agent.iterate()\n    if result.is_optimal():\n        break\n</code></pre> </li> </ul>"},{"location":"agents/#quick-start-example","title":"Quick Start Example","text":""},{"location":"agents/#simple-code-review-agent","title":"Simple Code Review Agent","text":"code_reviewer.py<pre><code>#!/usr/bin/env python3\n# /// script\n# requires-python = \"&gt;=3.9\"\n# dependencies = [\n#   \"openai\",\n#   \"anthropic\",\n#   \"rich\",\n#   \"click\",\n# ]\n# ///\n\n\"\"\"Security-focused code review agent\"\"\"\n\nimport click\nfrom rich.console import Console\nfrom pathlib import Path\nimport json\n\nconsole = Console()\n\nclass CodeReviewer:\n    \"\"\"AI-powered code review agent\"\"\"\n\n    def __init__(self, model=\"gpt-4\"):\n        self.model = model\n        self.issues = []\n\n    def review_file(self, file_path: Path):\n        \"\"\"Review a single file for issues\"\"\"\n        console.print(f\"[cyan]Reviewing:[/cyan] {file_path}\")\n\n        content = file_path.read_text()\n\n        # Security checks\n        security_issues = self.check_security(content)\n\n        # Style checks\n        style_issues = self.check_style(content)\n\n        # Complexity analysis\n        complexity = self.analyze_complexity(content)\n\n        return {\n            \"file\": str(file_path),\n            \"security\": security_issues,\n            \"style\": style_issues,\n            \"complexity\": complexity\n        }\n\n    def check_security(self, code):\n        \"\"\"Check for security vulnerabilities\"\"\"\n        issues = []\n\n        # Check for common vulnerabilities\n        if \"eval(\" in code:\n            issues.append(\"Use of eval() detected - security risk\")\n        if \"exec(\" in code:\n            issues.append(\"Use of exec() detected - security risk\")\n        if \"os.system(\" in code:\n            issues.append(\"Use of os.system() - consider subprocess\")\n\n        return issues\n\n    def check_style(self, code):\n        \"\"\"Check code style\"\"\"\n        issues = []\n\n        lines = code.split('\\n')\n        for i, line in enumerate(lines, 1):\n            if len(line) &gt; 100:\n                issues.append(f\"Line {i}: exceeds 100 characters\")\n\n        return issues\n\n    def analyze_complexity(self, code):\n        \"\"\"Analyze code complexity\"\"\"\n        lines = len(code.split('\\n'))\n\n        if lines &gt; 500:\n            return \"high\"\n        elif lines &gt; 200:\n            return \"medium\"\n        else:\n            return \"low\"\n\n    def generate_report(self, results):\n        \"\"\"Generate review report\"\"\"\n        console.print(\"\\n[bold cyan]Code Review Report[/bold cyan]\\n\")\n\n        for result in results:\n            console.print(f\"[yellow]{result['file']}[/yellow]\")\n\n            if result['security']:\n                console.print(\"  [red]Security Issues:[/red]\")\n                for issue in result['security']:\n                    console.print(f\"    \u2022 {issue}\")\n\n            if result['style']:\n                console.print(\"  [yellow]Style Issues:[/yellow]\")\n                for issue in result['style'][:3]:  # Show first 3\n                    console.print(f\"    \u2022 {issue}\")\n\n            console.print(f\"  Complexity: {result['complexity']}\\n\")\n\n@click.command()\n@click.argument('path', type=click.Path(exists=True))\n@click.option('--output', help='Save report to file')\ndef main(path, output):\n    \"\"\"AI-powered code review agent\"\"\"\n\n    reviewer = CodeReviewer()\n    path_obj = Path(path)\n\n    if path_obj.is_file():\n        results = [reviewer.review_file(path_obj)]\n    else:\n        results = []\n        for py_file in path_obj.rglob(\"*.py\"):\n            results.append(reviewer.review_file(py_file))\n\n    reviewer.generate_report(results)\n\n    if output:\n        with open(output, 'w') as f:\n            json.dump(results, f, indent=2)\n        console.print(f\"[green]Report saved to {output}[/green]\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"agents/#agent-patterns","title":"Agent Patterns","text":""},{"location":"agents/#1-single-purpose-agents","title":"1. Single-Purpose Agents","text":"<p>Focus on one task, do it well.</p>"},{"location":"agents/#2-composable-agents","title":"2. Composable Agents","text":"<p>Build complex systems from simple agents.</p>"},{"location":"agents/#3-stateful-agents","title":"3. Stateful Agents","text":"<p>Maintain context across interactions.</p>"},{"location":"agents/#4-learning-agents","title":"4. Learning Agents","text":"<p>Improve through feedback loops.</p>"},{"location":"agents/#agent-manager","title":"Agent Manager","text":"<p>Orchestrate multiple agents:</p> Python<pre><code>from loopy_agents import AgentManager, Agent\n\nclass DevelopmentTeam:\n    \"\"\"Coordinated development agents\"\"\"\n\n    def __init__(self):\n        self.manager = AgentManager()\n\n        # Register specialized agents\n        self.manager.register(\"architect\", ArchitectAgent())\n        self.manager.register(\"developer\", DeveloperAgent())\n        self.manager.register(\"tester\", TesterAgent())\n        self.manager.register(\"reviewer\", ReviewerAgent())\n\n    async def build_feature(self, requirements):\n        \"\"\"Build complete feature with all agents\"\"\"\n\n        # Phase 1: Architecture\n        design = await self.manager.run(\n            \"architect\", \n            f\"Design architecture for: {requirements}\"\n        )\n\n        # Phase 2: Implementation (parallel)\n        implementation, tests = await asyncio.gather(\n            self.manager.run(\"developer\", f\"Implement: {design}\"),\n            self.manager.run(\"tester\", f\"Write tests for: {design}\")\n        )\n\n        # Phase 3: Review\n        review = await self.manager.run(\n            \"reviewer\",\n            f\"Review code: {implementation}\"\n        )\n\n        return {\n            \"design\": design,\n            \"code\": implementation,\n            \"tests\": tests,\n            \"review\": review\n        }\n</code></pre>"},{"location":"agents/#best-practices","title":"Best Practices","text":"<p>UV for Dependencies</p> <p>Use UV's inline script dependencies for single-file agents</p> <p>Error Handling</p> <p>Always implement comprehensive error handling</p> <p>Monitoring</p> <p>Track agent performance and costs</p> <p>Context Management</p> <p>Keep context focused and relevant</p>"},{"location":"agents/#integration-points","title":"Integration Points","text":""},{"location":"agents/#with-hooks","title":"With Hooks","text":"<p>Agents can trigger hooks for validation: Python<pre><code># Agent calls trigger PreToolUse hooks\nagent.execute_tool(\"Bash\", {\"command\": \"test.sh\"})\n</code></pre></p>"},{"location":"agents/#with-mcp-servers","title":"With MCP Servers","text":"<p>Connect agents to multiple LLMs: Python<pre><code># Agent uses MCP for model selection\nagent.set_provider(\"openai\")\nagent.set_provider(\"anthropic\")\n</code></pre></p>"},{"location":"agents/#with-monitoring","title":"With Monitoring","text":"<p>Track all agent activity: Python<pre><code># Automatic monitoring integration\nmonitor.track_agent(agent_id, metrics)\n</code></pre></p>"},{"location":"agents/#next-steps","title":"Next Steps","text":"<ul> <li> <p>:material-file:{ .lg .middle } Single-File Agents</p> <p>Build self-contained agents</p> </li> <li> <p>:material-robot-multiple:{ .lg .middle } Multi-Agent Systems</p> <p>Orchestrate agent teams</p> </li> <li> <p>:material-microphone:{ .lg .middle } Voice Agents</p> <p>Create voice interfaces</p> </li> <li> <p>:material-lightbulb:{ .lg .middle } Agent Patterns</p> <p>Advanced patterns and techniques</p> </li> </ul>"},{"location":"hooks/","title":"Hooks Overview","text":"<p>Complete Control Over Claude Code</p> <p>Hooks provide deterministic control over Claude Code's behavior through 8 lifecycle events, allowing you to validate, modify, and control every aspect of the AI's actions.</p>"},{"location":"hooks/#what-are-hooks","title":"What Are Hooks?","text":"<p>Hooks are executable scripts that run at specific points in Claude Code's lifecycle. They receive JSON input via stdin and return JSON output to control execution flow.</p> <pre><code>graph LR\n    A[User Input] --&gt; B[UserPromptSubmit Hook]\n    B --&gt; C[Claude Processes]\n    C --&gt; D[PreToolUse Hook]\n    D --&gt; E[Tool Execution]\n    E --&gt; F[PostToolUse Hook]\n    F --&gt; G[Response]</code></pre>"},{"location":"hooks/#available-hooks","title":"Available Hooks","text":"<ul> <li> <p>:material-play-circle:{ .lg .middle } SessionStart</p> <p>Initializes your development environment when Claude Code starts</p> Python<pre><code>def session_start(event):\n    setup_environment()\n    load_context()\n</code></pre> </li> <li> <p>:material-text-box:{ .lg .middle } UserPromptSubmit</p> <p>Validates and enhances user prompts before processing</p> Python<pre><code>def user_prompt_submit(event):\n    prompt = enhance_prompt(event['prompt'])\n    return {\"prompt\": prompt}\n</code></pre> </li> <li> <p>:material-shield:{ .lg .middle } PreToolUse</p> <p>Security gate for all tool operations</p> Python<pre><code>def pre_tool_use(event):\n    if is_dangerous(event):\n        return {\"action\": \"block\"}\n</code></pre> </li> <li> <p>:material-check:{ .lg .middle } PostToolUse</p> <p>Validates and logs tool execution results</p> Python<pre><code>def post_tool_use(event):\n    log_result(event['result'])\n    validate_output(event)\n</code></pre> </li> </ul>"},{"location":"hooks/#quick-example","title":"Quick Example","text":"<p>Create <code>.claude/hooks/pre_tool_use.py</code>:</p> pre_tool_use.py<pre><code>#!/usr/bin/env python3\nimport json\nimport sys\n\ndef pre_tool_use_hook(event):\n    \"\"\"Security validation before tool execution\"\"\"\n\n    tool_name = event.get(\"tool_name\")\n    params = event.get(\"params\", {})\n\n    # Block dangerous bash commands\n    if tool_name == \"Bash\":\n        command = params.get(\"command\", \"\")\n        dangerous = [\"rm -rf\", \"sudo\", \"chmod 777\", \"curl | sh\"]\n\n        for danger in dangerous:\n            if danger in command:\n                return {\n                    \"action\": \"block\",\n                    \"message\": f\"Blocked dangerous command: {danger}\"\n                }\n\n    # Allow safe operations\n    return {\"action\": \"allow\"}\n\nif __name__ == \"__main__\":\n    event = json.loads(sys.stdin.read())\n    result = pre_tool_use_hook(event)\n    print(json.dumps(result))\n</code></pre>"},{"location":"hooks/#configuration","title":"Configuration","text":"<p>Configure hooks in <code>.claude/settings.json</code>:</p> JSON<pre><code>{\n  \"hooks\": {\n    \"preToolUse\": \".claude/hooks/pre_tool_use.py\",\n    \"postToolUse\": \".claude/hooks/post_tool_use.py\",\n    \"userPromptSubmit\": \".claude/hooks/user_prompt_submit.py\"\n  }\n}\n</code></pre>"},{"location":"hooks/#best-practices","title":"Best Practices","text":"<p>Security First</p> <p>Always implement <code>preToolUse</code> hooks to validate dangerous operations</p> <p>Error Handling</p> <p>Always return valid JSON, even on errors. Default to <code>{\"action\": \"allow\"}</code> to prevent blocking Claude</p> <p>Performance</p> <p>Keep hooks lightweight - they run synchronously and can impact response time</p>"},{"location":"hooks/#hook-communication","title":"Hook Communication","text":""},{"location":"hooks/#input-format","title":"Input Format","text":"JSON<pre><code>{\n  \"event_type\": \"pre_tool_use\",\n  \"tool_name\": \"Bash\",\n  \"params\": {\n    \"command\": \"ls -la\"\n  },\n  \"context\": {\n    \"session_id\": \"abc123\",\n    \"timestamp\": \"2025-01-01T00:00:00Z\"\n  }\n}\n</code></pre>"},{"location":"hooks/#response-format","title":"Response Format","text":"JSON<pre><code>{\n  \"action\": \"allow|block|modify\",\n  \"message\": \"Optional message\",\n  \"modified_params\": {}\n}\n</code></pre>"},{"location":"hooks/#integration-with-monitoring","title":"Integration with Monitoring","text":"<p>Hooks can send events to the monitoring dashboard:</p> Python<pre><code>import requests\n\ndef post_tool_use(event):\n    # Send to monitoring\n    requests.post(\"http://localhost:8080/events\", json={\n        \"type\": \"tool_executed\",\n        \"tool\": event[\"tool_name\"],\n        \"duration\": event[\"duration\"]\n    })\n\n    return {\"action\": \"allow\"}\n</code></pre>"},{"location":"hooks/#next-steps","title":"Next Steps","text":"<ul> <li> <p>:material-clock:{ .lg .middle } Lifecycle Events</p> <p>Deep dive into all 8 hook events</p> </li> <li> <p>:material-security:{ .lg .middle } Security Patterns</p> <p>Implement bulletproof security</p> </li> <li> <p>:material-code-braces:{ .lg .middle } Examples</p> <p>Production-ready hook implementations</p> </li> <li> <p>:material-bug:{ .lg .middle } Debugging</p> <p>Test and debug your hooks</p> </li> </ul>"},{"location":"hooks/lifecycle/","title":"Hook Lifecycle Events","text":""},{"location":"hooks/lifecycle/#complete-lifecycle-overview","title":"Complete Lifecycle Overview","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant C as Claude Code\n    participant H as Hooks\n    participant T as Tools\n\n    U-&gt;&gt;C: Start Session\n    C-&gt;&gt;H: SessionStart\n    U-&gt;&gt;C: Submit Prompt\n    C-&gt;&gt;H: UserPromptSubmit\n    C-&gt;&gt;C: Process Request\n    C-&gt;&gt;H: PreToolUse\n    C-&gt;&gt;T: Execute Tool\n    T-&gt;&gt;C: Result\n    C-&gt;&gt;H: PostToolUse\n    C-&gt;&gt;H: Notification\n    C-&gt;&gt;H: Stop\n    C-&gt;&gt;H: PreCompact (if needed)\n    C-&gt;&gt;U: Response</code></pre>"},{"location":"hooks/lifecycle/#1-sessionstart","title":"1. SessionStart","text":"<p>Triggered when a new Claude Code session begins.</p>"},{"location":"hooks/lifecycle/#use-cases","title":"Use Cases","text":"<ul> <li>Initialize development environment</li> <li>Load project context</li> <li>Set up monitoring</li> <li>Configure tools</li> </ul>"},{"location":"hooks/lifecycle/#example-implementation","title":"Example Implementation","text":"session_start.py<pre><code>#!/usr/bin/env python3\nimport json\nimport sys\nimport os\nfrom datetime import datetime\n\ndef session_start(event):\n    \"\"\"Initialize session with project context\"\"\"\n\n    session_id = event.get(\"session_id\")\n    project_path = event.get(\"project_path\", os.getcwd())\n\n    # Load project configuration\n    config = load_project_config(project_path)\n\n    # Initialize monitoring\n    init_monitoring(session_id)\n\n    # Set up environment\n    setup_environment(config)\n\n    # Log session start\n    log_event(\"session_started\", {\n        \"session_id\": session_id,\n        \"project\": project_path,\n        \"timestamp\": datetime.now().isoformat()\n    })\n\n    return {\n        \"action\": \"continue\",\n        \"context\": config\n    }\n\ndef load_project_config(path):\n    \"\"\"Load project-specific configuration\"\"\"\n    config_file = os.path.join(path, \".claude\", \"config.json\")\n    if os.path.exists(config_file):\n        with open(config_file, 'r') as f:\n            return json.load(f)\n    return {}\n\ndef init_monitoring(session_id):\n    \"\"\"Start monitoring for this session\"\"\"\n    # Initialize monitoring dashboard\n    pass\n\ndef setup_environment(config):\n    \"\"\"Configure environment based on project\"\"\"\n    # Set environment variables\n    # Configure tools\n    pass\n\ndef log_event(event_type, data):\n    \"\"\"Log to monitoring system\"\"\"\n    with open(\"claude_events.log\", 'a') as f:\n        f.write(json.dumps({\n            \"type\": event_type,\n            \"data\": data\n        }) + \"\\n\")\n\nif __name__ == \"__main__\":\n    event = json.loads(sys.stdin.read())\n    result = session_start(event)\n    print(json.dumps(result))\n</code></pre>"},{"location":"hooks/lifecycle/#2-userpromptsubmit","title":"2. UserPromptSubmit","text":"<p>Processes user input before Claude analyzes it.</p>"},{"location":"hooks/lifecycle/#features","title":"Features","text":"<ul> <li>Prompt enhancement</li> <li>Context injection</li> <li>Security validation</li> <li>Template expansion</li> </ul>"},{"location":"hooks/lifecycle/#example-implementation_1","title":"Example Implementation","text":"user_prompt_submit.py<pre><code>#!/usr/bin/env python3\nimport json\nimport sys\nimport re\n\ndef user_prompt_submit(event):\n    \"\"\"Enhance and validate user prompts\"\"\"\n\n    prompt = event.get(\"prompt\", \"\")\n    context = event.get(\"context\", {})\n\n    # Security check\n    if contains_sensitive_info(prompt):\n        return {\n            \"action\": \"block\",\n            \"message\": \"Prompt contains sensitive information\"\n        }\n\n    # Enhance prompt with context\n    enhanced_prompt = enhance_prompt(prompt, context)\n\n    # Add coding standards\n    if is_coding_request(prompt):\n        enhanced_prompt += \"\\n\\nPlease follow these standards:\\n\"\n        enhanced_prompt += \"- Include comprehensive error handling\\n\"\n        enhanced_prompt += \"- Add type hints for Python\\n\"\n        enhanced_prompt += \"- Write clear docstrings\\n\"\n        enhanced_prompt += \"- Include unit tests\\n\"\n\n    return {\n        \"action\": \"continue\",\n        \"prompt\": enhanced_prompt\n    }\n\ndef contains_sensitive_info(prompt):\n    \"\"\"Check for sensitive patterns\"\"\"\n    patterns = [\n        r'api[_-]?key',\n        r'password',\n        r'secret',\n        r'token',\n        r'credential'\n    ]\n\n    for pattern in patterns:\n        if re.search(pattern, prompt, re.IGNORECASE):\n            return True\n    return False\n\ndef enhance_prompt(prompt, context):\n    \"\"\"Add contextual information\"\"\"\n    enhanced = prompt\n\n    # Add project context\n    if context.get(\"project_type\"):\n        enhanced = f\"[Project: {context['project_type']}]\\n{enhanced}\"\n\n    # Expand templates\n    enhanced = expand_templates(enhanced)\n\n    return enhanced\n\ndef expand_templates(prompt):\n    \"\"\"Expand prompt templates\"\"\"\n    templates = {\n        \"@security\": \"Ensure security best practices including input validation and sanitization\",\n        \"@performance\": \"Optimize for performance and scalability\",\n        \"@test\": \"Include comprehensive unit and integration tests\"\n    }\n\n    for template, expansion in templates.items():\n        prompt = prompt.replace(template, expansion)\n\n    return prompt\n\ndef is_coding_request(prompt):\n    \"\"\"Detect if prompt is asking for code\"\"\"\n    coding_keywords = [\n        'function', 'class', 'implement', 'create', 'build',\n        'code', 'program', 'script', 'api', 'endpoint'\n    ]\n\n    prompt_lower = prompt.lower()\n    return any(keyword in prompt_lower for keyword in coding_keywords)\n\nif __name__ == \"__main__\":\n    event = json.loads(sys.stdin.read())\n    result = user_prompt_submit(event)\n    print(json.dumps(result))\n</code></pre>"},{"location":"hooks/lifecycle/#3-pretooluse","title":"3. PreToolUse","text":"<p>Critical security gate before any tool execution.</p>"},{"location":"hooks/lifecycle/#security-features","title":"Security Features","text":"<ul> <li>Command validation</li> <li>Path traversal prevention</li> <li>Resource limits</li> <li>Permission checking</li> </ul>"},{"location":"hooks/lifecycle/#example-implementation_2","title":"Example Implementation","text":"pre_tool_use.py<pre><code>#!/usr/bin/env python3\nimport json\nimport sys\nimport re\nimport os\nfrom pathlib import Path\n\nclass SecurityValidator:\n    \"\"\"Comprehensive security validation\"\"\"\n\n    DANGEROUS_COMMANDS = [\n        r'rm\\s+-rf\\s+/',\n        r'rm\\s+-rf\\s+~',\n        r'chmod\\s+777',\n        r'sudo\\s+',\n        r'curl.*\\|\\s*sh',\n        r'wget.*\\|\\s*sh',\n        r'eval\\(',\n        r'exec\\(',\n    ]\n\n    PROTECTED_PATHS = [\n        '/etc',\n        '/sys',\n        '/proc',\n        '~/.ssh',\n        '~/.aws',\n    ]\n\n    PROTECTED_FILES = [\n        '.env',\n        'credentials',\n        'secrets',\n        'private_key',\n    ]\n\n    def validate(self, event):\n        \"\"\"Main validation entry point\"\"\"\n        tool_name = event.get(\"tool_name\")\n        params = event.get(\"params\", {})\n\n        validators = {\n            \"Bash\": self.validate_bash,\n            \"Write\": self.validate_write,\n            \"Edit\": self.validate_edit,\n            \"MultiEdit\": self.validate_edit,\n            \"Delete\": self.validate_delete,\n        }\n\n        if tool_name in validators:\n            return validators[tool_name](params)\n\n        return {\"action\": \"allow\"}\n\n    def validate_bash(self, params):\n        \"\"\"Validate bash commands\"\"\"\n        command = params.get(\"command\", \"\")\n\n        # Check dangerous patterns\n        for pattern in self.DANGEROUS_COMMANDS:\n            if re.search(pattern, command, re.IGNORECASE):\n                return {\n                    \"action\": \"block\",\n                    \"message\": f\"Dangerous command pattern detected: {pattern}\"\n                }\n\n        # Check resource limits\n        if \"fork\" in command or \":(){ :|:&amp; };:\" in command:\n            return {\n                \"action\": \"block\",\n                \"message\": \"Fork bomb detected\"\n            }\n\n        return {\"action\": \"allow\"}\n\n    def validate_write(self, params):\n        \"\"\"Validate file write operations\"\"\"\n        file_path = params.get(\"file_path\", \"\")\n\n        # Check protected files\n        for protected in self.PROTECTED_FILES:\n            if protected in file_path.lower():\n                return {\n                    \"action\": \"block\",\n                    \"message\": f\"Cannot modify protected file: {protected}\"\n                }\n\n        # Check protected paths\n        for protected_path in self.PROTECTED_PATHS:\n            if file_path.startswith(protected_path):\n                return {\n                    \"action\": \"block\",\n                    \"message\": f\"Cannot write to protected path: {protected_path}\"\n                }\n\n        # Check path traversal\n        if \"../\" in file_path:\n            return {\n                \"action\": \"block\",\n                \"message\": \"Path traversal detected\"\n            }\n\n        return {\"action\": \"allow\"}\n\n    def validate_edit(self, params):\n        \"\"\"Validate file edit operations\"\"\"\n        return self.validate_write(params)\n\n    def validate_delete(self, params):\n        \"\"\"Validate delete operations\"\"\"\n        file_path = params.get(\"file_path\", \"\")\n\n        # Extra strict for deletions\n        if file_path == \"/\" or file_path == \"~\":\n            return {\n                \"action\": \"block\",\n                \"message\": \"Cannot delete root directories\"\n            }\n\n        return self.validate_write(params)\n\ndef pre_tool_use(event):\n    \"\"\"Main hook entry point\"\"\"\n    validator = SecurityValidator()\n    result = validator.validate(event)\n\n    # Log all tool use attempts\n    log_tool_use(event, result)\n\n    return result\n\ndef log_tool_use(event, result):\n    \"\"\"Log tool use for audit\"\"\"\n    import time\n    log_entry = {\n        \"timestamp\": time.time(),\n        \"tool\": event.get(\"tool_name\"),\n        \"params\": event.get(\"params\"),\n        \"result\": result[\"action\"]\n    }\n\n    with open(\"tool_audit.log\", 'a') as f:\n        f.write(json.dumps(log_entry) + \"\\n\")\n\nif __name__ == \"__main__\":\n    event = json.loads(sys.stdin.read())\n    result = pre_tool_use(event)\n    print(json.dumps(result))\n</code></pre>"},{"location":"hooks/lifecycle/#4-posttooluse","title":"4. PostToolUse","text":"<p>Validates and processes tool execution results.</p> post_tool_use.py<pre><code>#!/usr/bin/env python3\nimport json\nimport sys\nimport hashlib\n\ndef post_tool_use(event):\n    \"\"\"Process tool execution results\"\"\"\n\n    tool_name = event.get(\"tool_name\")\n    result = event.get(\"result\", {})\n    duration = event.get(\"duration_ms\", 0)\n\n    # Check for errors\n    if result.get(\"error\"):\n        handle_error(tool_name, result[\"error\"])\n\n    # Validate output\n    if not validate_output(tool_name, result):\n        return {\n            \"action\": \"retry\",\n            \"message\": \"Invalid output detected\"\n        }\n\n    # Track metrics\n    track_metrics(tool_name, duration)\n\n    # Cache results if appropriate\n    if should_cache(tool_name, event):\n        cache_result(event, result)\n\n    return {\"action\": \"continue\"}\n\ndef validate_output(tool_name, result):\n    \"\"\"Validate tool output\"\"\"\n    # Check for sensitive data in output\n    output_str = str(result)\n    sensitive_patterns = [\"password\", \"api_key\", \"secret\"]\n\n    for pattern in sensitive_patterns:\n        if pattern in output_str.lower():\n            # Redact sensitive information\n            result[\"output\"] = \"[REDACTED]\"\n            return True\n\n    return True\n\ndef track_metrics(tool_name, duration):\n    \"\"\"Track performance metrics\"\"\"\n    metrics = {\n        \"tool\": tool_name,\n        \"duration_ms\": duration,\n        \"timestamp\": time.time()\n    }\n\n    # Send to monitoring\n    send_to_monitoring(metrics)\n\ndef cache_result(event, result):\n    \"\"\"Cache for identical requests\"\"\"\n    cache_key = generate_cache_key(event)\n    # Store in cache\n    pass\n\ndef generate_cache_key(event):\n    \"\"\"Generate cache key from event\"\"\"\n    key_data = f\"{event['tool_name']}:{json.dumps(event['params'])}\"\n    return hashlib.sha256(key_data.encode()).hexdigest()\n\nif __name__ == \"__main__\":\n    event = json.loads(sys.stdin.read())\n    result = post_tool_use(event)\n    print(json.dumps(result))\n</code></pre>"},{"location":"hooks/lifecycle/#5-additional-lifecycle-events","title":"5. Additional Lifecycle Events","text":""},{"location":"hooks/lifecycle/#notification","title":"Notification","text":"<p>Handles Claude's notifications and alerts.</p>"},{"location":"hooks/lifecycle/#stop","title":"Stop","text":"<p>Executes when Claude finishes processing.</p>"},{"location":"hooks/lifecycle/#subagentstop","title":"SubagentStop","text":"<p>Manages subagent completion.</p>"},{"location":"hooks/lifecycle/#precompact","title":"PreCompact","text":"<p>Optimizes context before token limits.</p>"},{"location":"hooks/lifecycle/#hook-execution-order","title":"Hook Execution Order","text":"<ol> <li>SessionStart \u2192 Once per session</li> <li>UserPromptSubmit \u2192 Each user input</li> <li>PreToolUse \u2192 Before each tool</li> <li>PostToolUse \u2192 After each tool</li> <li>Notification \u2192 As needed</li> <li>Stop \u2192 End of processing</li> <li>SubagentStop \u2192 Subagent completion</li> <li>PreCompact \u2192 Context management</li> </ol>"},{"location":"hooks/lifecycle/#best-practices","title":"Best Practices","text":"<p>Chain of Responsibility</p> <p>Each hook should focus on a single responsibility</p> <p>Performance Impact</p> <p>Hooks run synchronously - keep them fast</p> <p>Fail Safe</p> <p>Always return valid JSON, default to allowing actions</p>"},{"location":"hooks/lifecycle/#next-security-patterns","title":"Next: Security Patterns \u2192","text":""},{"location":"mcp/","title":"MCP Servers Overview","text":"<p>Model Context Protocol</p> <p>MCP (Model Context Protocol) enables Claude Code to connect with external tools, databases, and APIs through a standardized interface.</p>"},{"location":"mcp/#what-is-mcp","title":"What is MCP?","text":"<p>The Model Context Protocol is an open standard for connecting AI assistants to external systems. It provides a unified way for Claude to interact with your tools and data sources.</p> <pre><code>graph LR\n    subgraph \"Claude Code\"\n        C[Claude]\n    end\n\n    subgraph \"MCP Layer\"\n        M[MCP Server]\n    end\n\n    subgraph \"External Systems\"\n        D[Databases]\n        A[APIs]\n        T[Tools]\n        F[Files]\n    end\n\n    C &lt;--&gt; M\n    M &lt;--&gt; D\n    M &lt;--&gt; A\n    M &lt;--&gt; T\n    M &lt;--&gt; F</code></pre>"},{"location":"mcp/#available-mcp-servers","title":"Available MCP Servers","text":"<ul> <li> <p>:material-cloud-sync:{ .lg .middle } Multi-Provider Server</p> <p>Connect to multiple LLM providers through one interface</p> JSON<pre><code>{\n  \"providers\": [\"openai\", \"anthropic\", \"groq\"],\n  \"models\": [\"gpt-4\", \"claude-3\", \"llama-3\"]\n}\n</code></pre> </li> <li> <p>:material-database:{ .lg .middle } Database Server</p> <p>Query and modify databases directly</p> SQL<pre><code>SELECT * FROM users \nWHERE created_at &gt; '2024-01-01'\n</code></pre> </li> <li> <p>:material-api:{ .lg .middle } API Gateway</p> <p>Interact with REST APIs and GraphQL endpoints</p> Python<pre><code>api.call(\"GET\", \"/users\", params={})\n</code></pre> </li> <li> <p>:material-folder:{ .lg .middle } File System</p> <p>Enhanced file operations with permissions</p> Python<pre><code>fs.read_secure(\"/protected/file.txt\")\n</code></pre> </li> </ul>"},{"location":"mcp/#quick-setup","title":"Quick Setup","text":""},{"location":"mcp/#1-install-mcp-server","title":"1. Install MCP Server","text":"Bash<pre><code># Clone the MCP server\ngit clone https://github.com/looptech-ai/mcp-servers.git\ncd mcp-servers\n\n# Install dependencies\npip install -r requirements.txt\n</code></pre>"},{"location":"mcp/#2-configure-claude-code","title":"2. Configure Claude Code","text":"<p>Add to <code>.claude/settings.json</code>:</p> JSON<pre><code>{\n  \"mcpServers\": {\n    \"multi-provider\": {\n      \"command\": \"python\",\n      \"args\": [\"mcp_servers/multi_provider/server.py\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"${OPENAI_API_KEY}\",\n        \"ANTHROPIC_API_KEY\": \"${ANTHROPIC_API_KEY}\"\n      }\n    },\n    \"database\": {\n      \"command\": \"python\",\n      \"args\": [\"mcp_servers/database/server.py\"],\n      \"env\": {\n        \"DATABASE_URL\": \"${DATABASE_URL}\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"mcp/#3-use-in-claude-code","title":"3. Use in Claude Code","text":"Bash<pre><code># List available MCP tools\nclaude mcp list\n\n# Use specific MCP server\nclaude --mcp multi-provider \"Compare responses from GPT-4 and Claude\"\n</code></pre>"},{"location":"mcp/#multi-provider-mcp-server","title":"Multi-Provider MCP Server","text":""},{"location":"mcp/#features","title":"Features","text":"<ul> <li>Unified interface for all LLM providers</li> <li>Automatic failover and retry logic</li> <li>Cost tracking per provider</li> <li>Response caching</li> </ul>"},{"location":"mcp/#example-implementation","title":"Example Implementation","text":"multi_provider_server.py<pre><code>#!/usr/bin/env python3\n\"\"\"Multi-provider MCP server for LLM access\"\"\"\n\nimport json\nimport os\nfrom typing import Dict, Any, List\nimport asyncio\nfrom dataclasses import dataclass\n\n@dataclass\nclass Provider:\n    \"\"\"LLM Provider configuration\"\"\"\n    name: str\n    api_key: str\n    base_url: str\n    models: List[str]\n\nclass MultiProviderMCP:\n    \"\"\"MCP server for multiple LLM providers\"\"\"\n\n    def __init__(self):\n        self.providers = self.load_providers()\n        self.cache = {}\n\n    def load_providers(self) -&gt; Dict[str, Provider]:\n        \"\"\"Load provider configurations\"\"\"\n        providers = {}\n\n        # OpenAI\n        if os.getenv(\"OPENAI_API_KEY\"):\n            providers[\"openai\"] = Provider(\n                name=\"openai\",\n                api_key=os.getenv(\"OPENAI_API_KEY\"),\n                base_url=\"https://api.openai.com/v1\",\n                models=[\"gpt-4\", \"gpt-3.5-turbo\"]\n            )\n\n        # Anthropic\n        if os.getenv(\"ANTHROPIC_API_KEY\"):\n            providers[\"anthropic\"] = Provider(\n                name=\"anthropic\",\n                api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n                base_url=\"https://api.anthropic.com/v1\",\n                models=[\"claude-3-opus\", \"claude-3-sonnet\"]\n            )\n\n        # Groq\n        if os.getenv(\"GROQ_API_KEY\"):\n            providers[\"groq\"] = Provider(\n                name=\"groq\",\n                api_key=os.getenv(\"GROQ_API_KEY\"),\n                base_url=\"https://api.groq.com/v1\",\n                models=[\"llama-3-70b\", \"mixtral-8x7b\"]\n            )\n\n        return providers\n\n    async def call_llm(self, provider: str, model: str, prompt: str) -&gt; Dict[str, Any]:\n        \"\"\"Call specific LLM through provider\"\"\"\n\n        # Check cache\n        cache_key = f\"{provider}:{model}:{hash(prompt)}\"\n        if cache_key in self.cache:\n            return self.cache[cache_key]\n\n        # Get provider\n        if provider not in self.providers:\n            raise ValueError(f\"Provider {provider} not configured\")\n\n        provider_obj = self.providers[provider]\n\n        # Make API call based on provider\n        if provider == \"openai\":\n            response = await self.call_openai(provider_obj, model, prompt)\n        elif provider == \"anthropic\":\n            response = await self.call_anthropic(provider_obj, model, prompt)\n        elif provider == \"groq\":\n            response = await self.call_groq(provider_obj, model, prompt)\n        else:\n            raise ValueError(f\"Unknown provider: {provider}\")\n\n        # Cache response\n        self.cache[cache_key] = response\n\n        return response\n\n    async def call_openai(self, provider: Provider, model: str, prompt: str) -&gt; Dict[str, Any]:\n        \"\"\"Call OpenAI API\"\"\"\n        import httpx\n\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\n                f\"{provider.base_url}/chat/completions\",\n                headers={\n                    \"Authorization\": f\"Bearer {provider.api_key}\",\n                    \"Content-Type\": \"application/json\"\n                },\n                json={\n                    \"model\": model,\n                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n                    \"temperature\": 0.7\n                }\n            )\n\n            return response.json()\n\n    async def call_anthropic(self, provider: Provider, model: str, prompt: str) -&gt; Dict[str, Any]:\n        \"\"\"Call Anthropic API\"\"\"\n        import httpx\n\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\n                f\"{provider.base_url}/messages\",\n                headers={\n                    \"x-api-key\": provider.api_key,\n                    \"anthropic-version\": \"2023-06-01\",\n                    \"Content-Type\": \"application/json\"\n                },\n                json={\n                    \"model\": model,\n                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n                    \"max_tokens\": 1000\n                }\n            )\n\n            return response.json()\n\n    async def compare_responses(self, prompt: str, providers: List[str] = None) -&gt; Dict[str, Any]:\n        \"\"\"Compare responses from multiple providers\"\"\"\n\n        if providers is None:\n            providers = list(self.providers.keys())\n\n        tasks = []\n        for provider in providers:\n            provider_obj = self.providers[provider]\n            model = provider_obj.models[0]  # Use first available model\n            tasks.append(self.call_llm(provider, model, prompt))\n\n        responses = await asyncio.gather(*tasks)\n\n        return {\n            \"prompt\": prompt,\n            \"responses\": dict(zip(providers, responses)),\n            \"comparison\": self.analyze_responses(responses)\n        }\n\n    def analyze_responses(self, responses: List[Dict[str, Any]]) -&gt; Dict[str, Any]:\n        \"\"\"Analyze and compare responses\"\"\"\n        # Compare response quality, length, etc.\n        analysis = {\n            \"count\": len(responses),\n            \"average_length\": sum(len(str(r)) for r in responses) / len(responses)\n        }\n\n        return analysis\n\n# MCP Server Interface\nclass MCPServer:\n    \"\"\"MCP server interface\"\"\"\n\n    def __init__(self):\n        self.multi_provider = MultiProviderMCP()\n\n    async def handle_request(self, request: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Handle MCP request\"\"\"\n\n        method = request.get(\"method\")\n        params = request.get(\"params\", {})\n\n        if method == \"call_llm\":\n            return await self.multi_provider.call_llm(\n                params[\"provider\"],\n                params[\"model\"],\n                params[\"prompt\"]\n            )\n        elif method == \"compare\":\n            return await self.multi_provider.compare_responses(\n                params[\"prompt\"],\n                params.get(\"providers\")\n            )\n        else:\n            raise ValueError(f\"Unknown method: {method}\")\n\n    def run(self):\n        \"\"\"Run MCP server\"\"\"\n        import sys\n\n        while True:\n            try:\n                # Read request from stdin\n                line = sys.stdin.readline()\n                if not line:\n                    break\n\n                request = json.loads(line)\n\n                # Process request\n                response = asyncio.run(self.handle_request(request))\n\n                # Write response to stdout\n                print(json.dumps(response))\n                sys.stdout.flush()\n\n            except Exception as e:\n                error_response = {\n                    \"error\": str(e),\n                    \"type\": type(e).__name__\n                }\n                print(json.dumps(error_response))\n                sys.stdout.flush()\n\nif __name__ == \"__main__\":\n    server = MCPServer()\n    server.run()\n</code></pre>"},{"location":"mcp/#best-practices","title":"Best Practices","text":"<p>Environment Variables</p> <p>Store API keys in environment variables, never hardcode</p> <p>Error Handling</p> <p>Implement retry logic and fallback providers</p> <p>Caching</p> <p>Cache responses to reduce API costs</p> <p>Monitoring</p> <p>Track usage and costs per provider</p>"},{"location":"mcp/#mcp-protocol-specification","title":"MCP Protocol Specification","text":""},{"location":"mcp/#request-format","title":"Request Format","text":"JSON<pre><code>{\n  \"method\": \"tool_name\",\n  \"params\": {\n    \"key\": \"value\"\n  },\n  \"id\": \"unique_request_id\"\n}\n</code></pre>"},{"location":"mcp/#response-format","title":"Response Format","text":"JSON<pre><code>{\n  \"result\": {\n    \"data\": \"response_data\"\n  },\n  \"id\": \"unique_request_id\"\n}\n</code></pre>"},{"location":"mcp/#available-mcp-servers_1","title":"Available MCP Servers","text":"<ol> <li>Multi-Provider - Connect to multiple LLMs</li> <li>Database - Database operations</li> <li>File System - Enhanced file operations</li> <li>Web Search - Internet search capabilities</li> <li>Custom Tools - Build your own</li> </ol>"},{"location":"mcp/#next-steps","title":"Next Steps","text":"<ul> <li> <p>:material-rocket-launch:{ .lg .middle } Quick Start</p> <p>Get started with MCP</p> </li> <li> <p>:material-server:{ .lg .middle } Custom Servers</p> <p>Build your own MCP server</p> </li> <li> <p>:material-integration:{ .lg .middle } Integration</p> <p>Integrate with Claude Code</p> </li> <li> <p>:material-api:{ .lg .middle } API Reference</p> <p>Complete API documentation</p> </li> </ul>"}]}